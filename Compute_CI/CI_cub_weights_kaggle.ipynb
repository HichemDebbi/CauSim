{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "67c8a2e1",
    "outputId": "938c8801-9ee8-417f-bc7f-17d7f636ac19"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a6834733"
   },
   "outputs": [],
   "source": [
    "\n",
    "import math\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow.keras\n",
    "import tensorflow.keras.layers\n",
    "import tensorflow.keras.applications\n",
    "import tensorflow.keras.backend\n",
    "import tensorflow.keras.preprocessing.image\n",
    "import tensorflow.keras.utils\n",
    "import tensorflow as tf\n",
    "\n",
    "import cv2\n",
    "import PIL\n",
    "import PIL.Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import shutil\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "\n",
    "# configurations\n",
    "\n",
    "## seeding\n",
    "os.environ['PYTHONHASHSEED'] = '3'\n",
    "np.random.seed(3)\n",
    "random.seed(3)\n",
    "tf.random.set_seed(3)\n",
    "\n",
    "## which gpu to use\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "## memory allocation\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    "session = tf.compat.v1.Session(config=config)\n",
    "#K.set_session(session)\n",
    "tf.compat.v1.keras.backend.set_session(session)\n",
    "## data directory for CUB200 root\n",
    "PATH_DATA_ROOT_CUB200 = \"/content/drive/My Drive/Colab Notebooks/Cub-200_BCNN/CUB_200_2011/CUB_200_2011\"\n",
    "\n",
    "## network configurations\n",
    "### number of output classes, 200 for CUB200\n",
    "NO_CLASS = 200\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6p6bZBI0T6Z6",
    "outputId": "f86a4b5b-9260-4702-a027-e1d67af5531c"
   },
   "outputs": [],
   "source": [
    "!ls \"/content/drive/My Drive/Colab Notebooks/Cub-200_BCNN/CUB_200_2011/CUB_200_2011\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OVe5c2pRIDDX"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.initializers import glorot_normal\n",
    "from keras.layers import Lambda\n",
    "\n",
    "def outer_product(x):\n",
    "    \"\"\"\n",
    "    calculate outer-products of 2 tensors\n",
    "\n",
    "        args \n",
    "            x\n",
    "                list of 2 tensors\n",
    "                , assuming each of which has shape = (size_minibatch, total_pixels, size_filter)\n",
    "    \"\"\"\n",
    "    return tensorflow.keras.backend.batch_dot(\n",
    "                x[0]\n",
    "                , x[1]\n",
    "                , axes=[1,1]\n",
    "            ) / x[0].get_shape().as_list()[1] \n",
    "\n",
    "def signed_sqrt(x):\n",
    "    \"\"\"\n",
    "    calculate element-wise signed square root\n",
    "\n",
    "        args\n",
    "            x\n",
    "                a tensor\n",
    "    \"\"\"\n",
    "    return tensorflow.keras.backend.sign(x) * tensorflow.keras.backend.sqrt(tensorflow.keras.backend.abs(x) + 1e-9)\n",
    "\n",
    "def L2_norm(x, axis=-1):\n",
    "    \"\"\"\n",
    "    calculate L2-norm\n",
    "\n",
    "        args \n",
    "            x\n",
    "                a tensor\n",
    "    \"\"\"\n",
    "    return tensorflow.keras.backend.l2_normalize(x, axis=axis)\n",
    "\n",
    "\n",
    "def build_model(filter_zero##added aprameter\n",
    "                ,value_filter\n",
    "    ,size_heigth=448\n",
    "    ,size_width=448\n",
    "    ,no_class=200\n",
    "    ,no_last_layer_backbone=17\n",
    "    \n",
    "    ,name_optimizer=\"sgd\"\n",
    "    ,rate_learning=1.0\n",
    "    ,rate_decay_learning=0.0\n",
    "    ,rate_decay_weight=0.0\n",
    "    \n",
    "    ,name_initializer=\"glorot_normal\"\n",
    "    ,name_activation_logits=\"softmax\"\n",
    "    ,name_loss=\"categorical_crossentropy\"\n",
    "    ,flg_debug=False\n",
    "    ,**kwargs\n",
    "):\n",
    "    \n",
    "    tensorflow.keras.backend.clear_session()\n",
    "    \n",
    "    # print(\"-------------------------------\")\n",
    "    # print(\"parameters:\")\n",
    "    # for key, val in locals().items():\n",
    "    #     if not val == None and not key == \"kwargs\":\n",
    "    #         print(\"\\t\", key, \"=\",  val)\n",
    "    # print(\"-------------------------------\")\n",
    "    \n",
    "    ### \n",
    "    ### load pre-trained model\n",
    "    ###\n",
    "    tensor_input = tensorflow.keras.layers.Input(shape=[size_heigth,size_width,3])\n",
    "    model_detector = tensorflow.keras.applications.vgg16.VGG16(\n",
    "                            input_tensor=tensor_input\n",
    "                            , include_top=False\n",
    "                            , weights='imagenet'\n",
    "                        )\n",
    "    \n",
    "    arryWeights_last_After =[]\n",
    "    for i in range(512):\n",
    "      arryWeights_last_After.append(i)\n",
    "    for i in range(512):\n",
    "      arryWeights_last_After[i]=1\n",
    "    \n",
    "    arryWeights_last_After[filter_zero]=value_filter\n",
    "    # print('filter' , filter_zero, \"=\", arryWeights_last_After[filter_zero])\n",
    "    def custom_layer_last(tensor):\n",
    "        return tensor * arryWeights_last_After\n",
    "    lambda_layer = Lambda (custom_layer_last, name=\"lambda_New\")\n",
    "\n",
    "    model_detector = insert_intermediate_layer_in_keras (model_detector, 18, lambda_layer)\n",
    "    # print('model detector')\n",
    "    # model_detector.summary()\n",
    "    ### \n",
    "    ### bi-linear pooling\n",
    "    ###\n",
    "\n",
    "    # extract features from detector\n",
    "    x_detector = model_detector.layers[no_last_layer_backbone].output\n",
    "    shape_detector = model_detector.layers[no_last_layer_backbone].output_shape\n",
    "    # if flg_debug:\n",
    "    #     print(\"shape_detector : {}\".format(shape_detector))\n",
    "\n",
    "    # extract features from extractor , same with detector for symmetry DxD model\n",
    "    shape_extractor = shape_detector\n",
    "    x_extractor = x_detector\n",
    "    # if flg_debug:\n",
    "    #     print(\"shape_extractor : {}\".format(shape_extractor))\n",
    "        \n",
    "    \n",
    "    # rehape to (minibatch_size, total_pixels, filter_size)\n",
    "    x_detector = tensorflow.keras.layers.Reshape(\n",
    "            [\n",
    "                shape_detector[1] * shape_detector[2] , shape_detector[-1]\n",
    "            ]\n",
    "        )(x_detector)\n",
    "    # if flg_debug:\n",
    "    #     print(\"x_detector shape after rehsape ops : {}\".format(x_detector.shape))\n",
    "        \n",
    "    x_extractor = tensorflow.keras.layers.Reshape(\n",
    "            [\n",
    "                shape_extractor[1] * shape_extractor[2] , shape_extractor[-1]\n",
    "            ]\n",
    "        )(x_extractor)\n",
    "    # if flg_debug:\n",
    "    #     print(\"x_extractor shape after rehsape ops : {}\".format(x_extractor.shape))\n",
    "        \n",
    "        \n",
    "    # outer products of features, output shape=(minibatch_size, filter_size_detector*filter_size_extractor)\n",
    "    x = tensorflow.keras.layers.Lambda(outer_product)(\n",
    "        [x_detector, x_extractor]\n",
    "    )\n",
    "    # if flg_debug:\n",
    "    #     print(\"x shape after outer products ops : {}\".format(x.shape))\n",
    "        \n",
    "        \n",
    "    # rehape to (minibatch_size, filter_size_detector*filter_size_extractor)\n",
    "    x = tensorflow.keras.layers.Reshape([shape_detector[-1]*shape_extractor[-1]])(x)\n",
    "    # if flg_debug:\n",
    "    #     print(\"x shape after rehsape ops : {}\".format(x.shape))\n",
    "        \n",
    "        \n",
    "    # signed square-root \n",
    "    x = tensorflow.keras.layers.Lambda(signed_sqrt)(x)\n",
    "    # if flg_debug:\n",
    "    #     print(\"x shape after signed-square-root ops : {}\".format(x.shape))\n",
    "        \n",
    "    # L2 normalization\n",
    "    x = tensorflow.keras.layers.Lambda(L2_norm)(x)\n",
    "    # if flg_debug:\n",
    "    #     print(\"x shape after L2-Normalization ops : {}\".format(x.shape))\n",
    "\n",
    "\n",
    "\n",
    "    ### \n",
    "    ### attach FC-Layer\n",
    "    ###\n",
    "\n",
    "    if name_initializer != None:\n",
    "            name_initializer = eval(name_initializer+\"()\")\n",
    "            \n",
    "    x = tensorflow.keras.layers.Dense(\n",
    "            units=no_class\n",
    "            ,kernel_regularizer=tensorflow.keras.regularizers.l2(rate_decay_weight)\n",
    "            ,kernel_initializer=name_initializer\n",
    "        )(x)\n",
    "    # if flg_debug:\n",
    "    #     print(\"x shape after Dense ops : {}\".format(x.shape))\n",
    "    tensor_prediction = tensorflow.keras.layers.Activation(name_activation_logits)(x)\n",
    "    # if flg_debug:\n",
    "    #     print(\"prediction shape : {}\".format(tensor_prediction.shape))\n",
    "\n",
    "        \n",
    "\n",
    "    ### \n",
    "    ### compile model\n",
    "    ###\n",
    "    model_bilinear = tensorflow.keras.models.Model(\n",
    "                        inputs=[tensor_input]\n",
    "                        , outputs=[tensor_prediction]\n",
    "                    )\n",
    "    \n",
    "    \n",
    "    # fix pre-trained weights\n",
    "    for layer in model_detector.layers:\n",
    "        layer.trainable = False\n",
    "        \n",
    "        \n",
    "    # define optimizers\n",
    "    opt_adam = tensorflow.keras.optimizers.Adam(\n",
    "                    lr=rate_learning\n",
    "                    , decay=rate_decay_learning\n",
    "                )\n",
    "    opt_rms = tensorflow.keras.optimizers.RMSprop(\n",
    "                    lr=rate_learning\n",
    "                    , decay=rate_decay_learning\n",
    "                )\n",
    "    opt_sgd = tensorflow.keras.optimizers.SGD(\n",
    "                    lr=rate_learning\n",
    "                    , decay=rate_decay_learning\n",
    "                    , momentum=0.9\n",
    "                    , nesterov=False\n",
    "                )\n",
    "    optimizers ={\n",
    "        \"adam\":opt_adam\n",
    "        ,\"rmsprop\":opt_rms\n",
    "        ,\"sgd\":opt_sgd\n",
    "    }\n",
    "    \n",
    "    model_bilinear.compile(\n",
    "        loss=name_loss\n",
    "        , optimizer=optimizers[name_optimizer]\n",
    "        , metrics=[\"categorical_accuracy\"]\n",
    "    )\n",
    "    \n",
    "    \n",
    "    \n",
    "    # if flg_debug:\n",
    "    #     model_bilinear.summary()\n",
    "    \n",
    "    return model_bilinear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RNxrj3bsuDa3"
   },
   "outputs": [],
   "source": [
    "def insert_intermediate_layer_in_keras(model, layer_id, new_layer):\n",
    "    from keras.models import Model\n",
    "\n",
    "    layers = [l for l in model.layers]\n",
    "\n",
    "    x = layers[0].output\n",
    "    for i in range(1, len(layers)):\n",
    "        if i == layer_id:\n",
    "            x = new_layer(x)\n",
    "        x = layers[i](x)\n",
    "\n",
    "    model = Model(inputs=layers[0].input, outputs=x) ### inputs instead of input in this version\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pCFrXeiHIHqZ",
    "outputId": "bd22e071-bfa8-4e6e-fa40-48edae36c5db"
   },
   "outputs": [],
   "source": [
    "model = build_model(filter_zero=0\n",
    "                    , value_filter=1\n",
    "            # number of output classes, 200 for CUB200\n",
    "            ,no_class = NO_CLASS\n",
    "\n",
    "            # pretrained model specification, using VGG16\n",
    "            # \"block5_conv3 \"\n",
    "            ,no_last_layer_backbone = 18\n",
    "\n",
    "            # training parametes\n",
    "            ,rate_learning=1.0\n",
    "            ,rate_decay_weight=1e-8\n",
    "            ,flg_debug=True\n",
    "        )\n",
    "\n",
    "# model = build_model(\n",
    "#             # number of output classes, 200 for CUB200\n",
    "#             no_class = NO_CLASS\n",
    "\n",
    "#             # pretrained model specification, using VGG16\n",
    "#             # \"block5_conv3 \"\n",
    "#             ,no_last_layer_backbone = 17           \n",
    "#             # training parametes\n",
    "#             ,rate_learning=1.0\n",
    "#             ,rate_decay_weight=1e-8\n",
    "#             ,flg_debug=True\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KMKjEP9_IMPc",
    "outputId": "a0592b68-c420-41c0-95ce-d1fb229378f4"
   },
   "outputs": [],
   "source": [
    "# now all layers are trainable\n",
    "for layer in model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "# change LR\n",
    "opt_sgd = tensorflow.keras.optimizers.SGD(\n",
    "                lr=1e-3\n",
    "                , decay=1e-9\n",
    "                , momentum=0.9\n",
    "                , nesterov=False\n",
    "            )\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\"\n",
    "    , optimizer=opt_sgd\n",
    "    , metrics=[\"categorical_accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "00HJQdW2H2o2"
   },
   "outputs": [],
   "source": [
    "model.load_weights(\"/content/drive/My Drive/Colab Notebooks/Cub-200_BCNN/birds_200_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8vImZhwnIpoR",
    "outputId": "15fcf0a1-9b0b-416b-ede6-3f9cc36e33d9"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "birds_labels = set()\n",
    "\n",
    "path= \"/content/drive/My Drive/Colab Notebooks/Cub-200_BCNN/CUB_200_2011/CUB_200_2011/images\"\n",
    "for d in os.listdir(path):\n",
    "    birds_labels.add(d)\n",
    "\n",
    "len(birds_labels)\n",
    "\n",
    "# print(birds_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qE1xOo-oWCLd"
   },
   "outputs": [],
   "source": [
    "birds_labels = list(birds_labels)\n",
    "birds_labels.sort()\n",
    "# birds_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NMp698AKOpJB"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "def load_and_preprocess_image(path):\n",
    "    image = cv2.imread(path)\n",
    "    image = cv2.resize(image, (448,448))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lab29cnkOwYb"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "import numpy as np\n",
    "\n",
    "def output(location, new_model):\n",
    "    img = load_and_preprocess_image(location)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    answer = new_model.predict(img)\n",
    "    y_class = answer.argmax(axis = -1)\n",
    "    \n",
    "    top_3 = np.argsort(answer[0])[:-4:-1]\n",
    "    # for i in range(3):\n",
    "    #     print(\" ({:.3})\".format(answer[0][top_3[i]]))\n",
    "    \n",
    "    y = \" \".join(str(x) for x in y_class)\n",
    "    y = int(y)\n",
    "    res = birds_labels[y]\n",
    "    # print(res)\n",
    "#     print(\" ({:.3})\".format(answer[0][top_3[0]]))\n",
    "    pred_prob = answer[0][top_3[0]]\n",
    "    return float(pred_prob), res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iKDdp8itOuEw",
    "outputId": "4c8b1cb1-081c-4d89-8bc7-f02b117015f4"
   },
   "outputs": [],
   "source": [
    "location = \"/content/drive/My Drive/Colab Notebooks/Cub-200_BCNN/Birds_classes_top/011.Rusty_Blackbird/Rusty_Blackbird_0091_6695.jpg\"\n",
    "output(location, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose top prototypes for causal learning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "54JgMKwlPuDy"
   },
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import os\n",
    "# from shutil import copyfile\n",
    "# from pathlib import Path\n",
    "\n",
    "# folder = \"/content/drive/My Drive/Colab Notebooks/Cub-200_BCNN/CUB_200_2011/CUB_200_2011/images/\"\n",
    "# folder_Copy = \"/content/drive/My Drive/Colab Notebooks/Cub-200_BCNN/Birds_classes_top/\"\n",
    "\n",
    "# last_fileName=\"\"\n",
    "\n",
    "# #images = []\n",
    "# imagesFileNames = []\n",
    "# for filename in os.listdir(folder):\n",
    "#     if filename not in os.listdir(folder_Copy):\n",
    "#         for img in os.listdir(folder+filename):\n",
    "#             if output(folder+filename+\"/\"+img, model)[0] >= 0.9 :\n",
    "#                 if output(folder+filename+\"/\"+img, model)[1] ==  filename:\n",
    "#                     print('path', folder+filename+\"/\"+img)\n",
    "#                     print('prob=', output(folder+filename+\"/\"+img, model)[0])\n",
    "#                     src = folder+filename+\"/\"+img\n",
    "#                     dst = folder_Copy+filename+\"/\"+img\n",
    "#                     Path(folder_Copy+filename+\"/\").mkdir(parents=True, exist_ok=True)\n",
    "#                     copyfile(src, dst)\n",
    "#                     print(filename)\n",
    "#         #             print(img)\n",
    "#                     break;\n",
    "#     #     img = cv2.imread(os.path.join(folder,filename))\n",
    "#     #     if img is not None:\n",
    "#     #         #images.append(img)\n",
    "#         imagesFileNames.append(filename)\n",
    "# imagesFileNames.sort()        \n",
    "# print(imagesFileNames[0])\n",
    "# #images = load_images_from_folder(folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4NhSJHCzkNUu",
    "outputId": "511a31dc-3e2c-40e2-d4ac-7347fcf55849"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "from shutil import copyfile\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "folder = \"/content/drive/My Drive/Colab Notebooks/Cub-200_BCNN/Birds_classes_top/\"\n",
    "\n",
    "last_fileName=\"\"\n",
    "#images = []\n",
    "imagesFileNames = []\n",
    "for filename in os.listdir(folder):\n",
    "    # for img in os.listdir(folder+filename):\n",
    "    imagesFileNames.append(filename)\n",
    "    print(filename)\n",
    "# imagesFileNames.sort()\n",
    "print(len(imagesFileNames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b4pekaqMkdRE"
   },
   "outputs": [],
   "source": [
    "# arryWeights_last_After =[]\n",
    "# for i in range(512):\n",
    "#   arryWeights_last_After.append(i)\n",
    "# for i in range(512):\n",
    "#   arryWeights_last_After[i]=1\n",
    "\n",
    "# def custom_layer_last(tensor):\n",
    "#     return tensor * arryWeights_last_After[i]\n",
    "# # vgg_weights = VGG16(    input_shape = IMAGE_SIZE + [3], weights = 'imagenet',\n",
    "# #     include_top = False).get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This part for computing the CI and storing it into Dictionnary in tx file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ViEY2uugklO7",
    "outputId": "1c7162e8-047a-427d-b2ba-58cabfe98bc4"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Lambda\n",
    "from keras import backend as K\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D, MaxPool2D \n",
    "\n",
    "\n",
    "weights_dic = {}\n",
    "\n",
    "imgCount = 0\n",
    "indexImg=0\n",
    "# img_path = 'Mountain_Bike/[image-net.org][27]443691662_09f12b8e37.jpg'\n",
    "for imgFileName in imagesFileNames:\n",
    "    dctOfAllDictionClasses = {}\n",
    "    imgPath = folder + imagesFileNames[indexImg] + \"/\" + os.listdir(folder + imagesFileNames[indexImg])[0]\n",
    "    print(imgPath)\n",
    "    res = output(imgPath, model)\n",
    "\n",
    "    originalName = imgFileName\n",
    "    print('orign name:', originalName)\n",
    "    class_Id = res[1]\n",
    "    orig_acc = res[0]\n",
    "    print('origin acc', orig_acc)\n",
    "    from keras.layers import Lambda\n",
    "    weights_dic = {}\n",
    "    K.set_learning_phase(0)\n",
    "    \n",
    "    import time\n",
    "    start_time = time.time()\n",
    "    for i in range(512):\n",
    "        print ('filt{}'.format (i))\n",
    "        filt = i\n",
    "\n",
    "        new_model = build_model( filter_zero=i##added aprameter\n",
    "            ,value_filter =0\n",
    "            # number of output classes, 200 for CUB200\n",
    "            ,no_class = NO_CLASS\n",
    "\n",
    "            # pretrained model specification, using VGG16\n",
    "            # \"block5_conv3 \"\n",
    "            ,no_last_layer_backbone = 18\n",
    "                        # training parametes\n",
    "            ,rate_learning=1.0\n",
    "            ,rate_decay_weight=1e-8\n",
    "            ,flg_debug=True\n",
    "        )\n",
    "\n",
    "                # now all layers are trainable\n",
    "        for layer in new_model.layers:\n",
    "            layer.trainable = True\n",
    "\n",
    "        # change LR\n",
    "        opt_sgd = tensorflow.keras.optimizers.SGD(\n",
    "                        lr=1e-3\n",
    "                        , decay=1e-9\n",
    "                        , momentum=0.9\n",
    "                        , nesterov=False\n",
    "                    )\n",
    "        new_model.compile(\n",
    "            loss=\"categorical_crossentropy\"\n",
    "            , optimizer=opt_sgd\n",
    "            , metrics=[\"categorical_accuracy\"]\n",
    "        )\n",
    "        new_model.load_weights('/content/drive/My Drive/Colab Notebooks/Cub-200_BCNN/birds_200_weights.h5')\n",
    "\n",
    "        new_res = output(imgPath, new_model)\n",
    "        # print('res[0]', new_res[0])\n",
    "        # print('res[1]', new_res[1])\n",
    "    \n",
    "        New_accu = new_res[0]\n",
    "        print(\" ({:.3})\".format(New_accu))\n",
    "        print('label name:', new_res[1])\n",
    "        print ('acc after purning (%.2f%%)', New_accu)\n",
    "        print('difference: ', (orig_acc - New_accu))\n",
    "        #weights_dic[filt][0] = 1/(k+1)  # resp\n",
    "        tuple = orig_acc - New_accu, 1\n",
    "        #weights_dic[filt] = original_loss[1] - loss[1]  # prob\n",
    "        weights_dic[filt] = tuple\n",
    "        # arryWeights_last_After[i]=1\n",
    "        K.clear_session ()\n",
    "\n",
    "    weights_dic_sort = sorted (weights_dic.items (), key=lambda kv: kv[1], reverse=True)\n",
    "    print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "    pairKeyValue = { originalName: weights_dic_sort}\n",
    "    dctOfAllDictionClasses = {}\n",
    "    dctOfAllDictionClasses.update(pairKeyValue)\n",
    "    print('pair ley:', pairKeyValue)\n",
    "    import json\n",
    "    with open('/content/drive/My Drive/Colab Notebooks/Cub-200_BCNN/Filt_Resp_Birds_BCNN.txt', 'a') as fout:\n",
    "\n",
    "        fout.write(\"\\n\" + str(dctOfAllDictionClasses) + \"\\n\") \n",
    "        print('Last Image ID:', imagesFileNames[imgCount])\n",
    "    imgCount+=1\n",
    "    indexImg+=1\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "birds-cub-weights_kaggle.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 16.722354,
   "end_time": "2021-09-18T20:19:30.986221",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-09-18T20:19:14.263867",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
